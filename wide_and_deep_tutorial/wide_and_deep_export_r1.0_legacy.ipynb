{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Wide & Deep Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categorical base columns.\n",
    "gender = tf.contrib.layers.sparse_column_with_keys(column_name=\"gender\", keys=[\"Female\", \"Male\"])\n",
    "race = tf.contrib.layers.sparse_column_with_keys(column_name=\"race\", keys=[\n",
    "  \"Amer-Indian-Eskimo\", \"Asian-Pac-Islander\", \"Black\", \"Other\", \"White\"])\n",
    "education = tf.contrib.layers.sparse_column_with_hash_bucket(\"education\", hash_bucket_size=1000)\n",
    "relationship = tf.contrib.layers.sparse_column_with_hash_bucket(\"relationship\", hash_bucket_size=100)\n",
    "workclass = tf.contrib.layers.sparse_column_with_hash_bucket(\"workclass\", hash_bucket_size=100)\n",
    "occupation = tf.contrib.layers.sparse_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)\n",
    "native_country = tf.contrib.layers.sparse_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)\n",
    "\n",
    "# Continuous base columns.\n",
    "age = tf.contrib.layers.real_valued_column(\"age\")\n",
    "age_buckets = tf.contrib.layers.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "education_num = tf.contrib.layers.real_valued_column(\"education_num\")\n",
    "capital_gain = tf.contrib.layers.real_valued_column(\"capital_gain\")\n",
    "capital_loss = tf.contrib.layers.real_valued_column(\"capital_loss\")\n",
    "hours_per_week = tf.contrib.layers.real_valued_column(\"hours_per_week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_columns = [\n",
    "  gender, native_country, education, occupation, workclass, relationship, age_buckets,\n",
    "  tf.contrib.layers.crossed_column([education, occupation], hash_bucket_size=int(1e4)),\n",
    "  tf.contrib.layers.crossed_column([native_country, occupation], hash_bucket_size=int(1e4)),\n",
    "  tf.contrib.layers.crossed_column([age_buckets, education, occupation], hash_bucket_size=int(1e6))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n"
     ]
    }
   ],
   "source": [
    "deep_columns = [\n",
    "  tf.contrib.layers.embedding_column(workclass, dimension=8),\n",
    "  tf.contrib.layers.embedding_column(education, dimension=8),\n",
    "  tf.contrib.layers.embedding_column(gender, dimension=8),\n",
    "  tf.contrib.layers.embedding_column(relationship, dimension=8),\n",
    "  tf.contrib.layers.embedding_column(native_country, dimension=8),\n",
    "  tf.contrib.layers.embedding_column(occupation, dimension=8),\n",
    "  age, education_num, capital_gain, capital_loss, hours_per_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_task_type': None, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_log_step_count_steps': 100, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10fb7ff60>, '_num_ps_replicas': 0, '_tf_random_seed': None, '_model_dir': '/var/folders/qv/glzl2pyj2g15vz3tn5s52c9w0000gn/T/tmpbqbm7dpx', '_environment': 'local', '_save_summary_steps': 100, '_evaluation_master': '', '_num_worker_replicas': 0, '_session_config': None, '_is_chief': True, '_save_checkpoints_steps': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_dir = tempfile.mkdtemp()\n",
    "m = tf.contrib.learn.DNNLinearCombinedClassifier(\n",
    "    model_dir=model_dir,\n",
    "    linear_feature_columns=wide_columns,\n",
    "    dnn_feature_columns=deep_columns,\n",
    "    dnn_hidden_units=[100, 50],\n",
    "    fix_global_step_increment_bug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column names for the data sets.\n",
    "COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "  \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "  \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income_bracket\"]\n",
    "LABEL_COLUMN = 'label'\n",
    "CATEGORICAL_COLUMNS = [\"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
    "                       \"relationship\", \"race\", \"gender\", \"native_country\"]\n",
    "CONTINUOUS_COLUMNS = [\"age\", \"education_num\", \"capital_gain\", \"capital_loss\",\n",
    "                      \"hours_per_week\"]\n",
    "\n",
    "# Download the training and test data to temporary files.\n",
    "# Alternatively, you can download them yourself and change train_file and\n",
    "# test_file to your own paths.\n",
    "train_file = tempfile.NamedTemporaryFile()\n",
    "test_file = tempfile.NamedTemporaryFile()\n",
    "urllib.request.urlretrieve(\"http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.data\", train_file.name)\n",
    "urllib.request.urlretrieve(\"http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.test\", test_file.name)\n",
    "\n",
    "# Read the training and test data sets into Pandas dataframe.\n",
    "df_train = pd.read_csv(train_file, names=COLUMNS, skipinitialspace=True)\n",
    "df_test = pd.read_csv(test_file, names=COLUMNS, skipinitialspace=True, skiprows=1)\n",
     "# If you want to do predictions locally. Put the data in a csv file in the same format as train/test file.\n",
    "#df_predict = pd.read_csv(predict_file, names=COLUMNS, skipinitialspace=True)\n",
    "\n",
    "df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)\n",
    "df_test[LABEL_COLUMN] = (df_test['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)\n",
    "\n",
    "def input_fn(df, predict = False):\n",
    "    # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "    # the values of that column stored in a constant Tensor.\n",
    "    continuous_cols = {k: tf.constant(df[k].values)\n",
    "                       for k in CONTINUOUS_COLUMNS}\n",
    "    # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "    # to the values of that column stored in a tf.SparseTensor.\n",
    "    categorical_cols = {k: tf.SparseTensor(\n",
    "        indices=[[i, 0] for i in range(df[k].size)],\n",
    "        values=df[k].values,\n",
    "        dense_shape=[df[k].size, 1])\n",
    "                        for k in CATEGORICAL_COLUMNS}\n",
    "    # Merges the two dictionaries into one.\n",
    "    feature_cols = dict(list(continuous_cols.items()) +\n",
    "                        list(categorical_cols.items()))\n",
    "    \n",
    "    # Returns the feature columns and the label.\n",
    "    if predict == True:\n",
    "        return feature_cols\n",
    "    else:\n",
    "        # Converts the label column into a constant Tensor.\n",
    "        label = tf.constant(df[LABEL_COLUMN].values)\n",
    "        return feature_cols, label\n",
    "\n",
    "def train_input_fn():\n",
    "    return input_fn(df_train)\n",
    "\n",
    "def eval_input_fn():\n",
    "    return input_fn(df_test)\n",
    "\n",
    "def predict_input_fn():\n",
    "    return input_fn(df_predict, predict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /Users/mrdantsev/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:From /Users/mrdantsev/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:From /Users/mrdantsev/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:From /Users/mrdantsev/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/qv/glzl2pyj2g15vz3tn5s52c9w0000gn/T/tmpbqbm7dpx/model.ckpt.\n",
      "INFO:tensorflow:loss = 35.4585, step = 1\n",
      "INFO:tensorflow:global_step/sec: 5.78725\n",
      "INFO:tensorflow:loss = 0.504971, step = 101 (17.289 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/qv/glzl2pyj2g15vz3tn5s52c9w0000gn/T/tmpbqbm7dpx/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.696558.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /Users/mrdantsev/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:From /Users/mrdantsev/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:From /Users/mrdantsev/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:From /Users/mrdantsev/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-07-00:17:51\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/qv/glzl2pyj2g15vz3tn5s52c9w0000gn/T/tmpbqbm7dpx/model.ckpt-200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-07-00:17:54\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.849579, accuracy/baseline_label_mean = 0.236226, accuracy/threshold_0.500000_mean = 0.849579, auc = 0.879309, auc_precision_recall = 0.749818, global_step = 200, labels/actual_label_mean = 0.236226, labels/prediction_mean = 0.219003, loss = 0.376738, precision/positive_threshold_0.500000_mean = 0.775325, recall/positive_threshold_0.500000_mean = 0.51144\n",
      "accuracy: 0.849579\n",
      "accuracy/baseline_label_mean: 0.236226\n",
      "accuracy/threshold_0.500000_mean: 0.849579\n",
      "auc: 0.879309\n",
      "auc_precision_recall: 0.749818\n",
      "global_step: 200\n",
      "labels/actual_label_mean: 0.236226\n",
      "labels/prediction_mean: 0.219003\n",
      "loss: 0.376738\n",
      "precision/positive_threshold_0.500000_mean: 0.775325\n",
      "recall/positive_threshold_0.500000_mean: 0.51144\n"
     ]
    }
   ],
   "source": [
    "m.fit(input_fn=train_input_fn, steps=200)\n",
    "results = m.evaluate(input_fn=eval_input_fn, steps=1)\n",
    "for key in sorted(results):\n",
    "    print(\"%s: %s\" % (key, results[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict the Tensorflow Model Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [0.80336, 0.19664]\n",
      "0 : [0.61142, 0.38858]\n",
      "0 : [0.79919, 0.20081]\n",
      "1 : [0.00084, 0.99916]\n",
      "0 : [0.85656, 0.14344]\n",
      "0 : [0.74078, 0.25922]\n",
      "0 : [0.75243, 0.24757]\n",
      "0 : [0.55772, 0.44228]\n"
     ]
    }
   ],
   "source": [
    "# predict_file = \"adult.predict.csv\"\n",
    "pre_results = m.predict_classes(input_fn=predict_input_fn)\n",
    "pre_results_prob = m.predict_proba(input_fn=predict_input_fn)\n",
    "for key,pro in zip(pre_results,pre_results_prob):\n",
    "    print \"%s : %s\"%(key,[round(p,5) for p in pro])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Export TensorFlow Model using .export_savedmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import this function from wherever it will end up in the future\n",
    "from tensorflow.contrib.learn.python.learn.utils import input_fn_utils\n",
    "from tensorflow.contrib.layers import create_feature_spec_for_parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mrdantsev/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:From /Users/mrdantsev/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:From /Users/mrdantsev/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/qv/glzl2pyj2g15vz3tn5s52c9w0000gn/T/tmpbqbm7dpx/model.ckpt-200\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'./serving_savemodel/1504743714/saved_model.pb'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'./serving_savemodel/1504743714'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I step\n",
    "feature_columns = wide_columns + deep_columns\n",
    "\n",
    "# II step\n",
    "feature_spec = create_feature_spec_for_parsing(feature_columns)\n",
    "\n",
    "# III step\n",
    "export_input_fn = input_fn_utils.build_parsing_serving_input_fn(feature_spec)\n",
    "\n",
    "# IV step\n",
    "servable_model_dir = \"./serving_savemodel\"\n",
    "servable_model_path = m.export_savedmodel(servable_model_dir, export_input_fn)\n",
    "servable_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
